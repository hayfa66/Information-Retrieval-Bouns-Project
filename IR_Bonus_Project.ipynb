{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Bouns project for information retrieval course\n",
        "\n",
        "Hayfa Al-ajmi submission."
      ],
      "metadata": {
        "id": "THadE99HXO9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook contents\n",
        "\n",
        "1. dataset\n",
        "\n",
        "2. dictionary\n",
        "\n",
        "3. posting lists\n",
        "\n",
        "4. compression\n",
        "\n",
        "5. conclusion"
      ],
      "metadata": {
        "id": "Iy-mQK44Fn6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset :\n",
        "\n",
        "the dataset is ~15,000 movies-feedback-tweets from twitter."
      ],
      "metadata": {
        "id": "w-2dzDY_idOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from nltk.stem import PorterStemmer as ps\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "3j260UI_nCq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets.csv\",encoding='latin1')"
      ],
      "metadata": {
        "id": "MlSuNH2TnH6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dictionary"
      ],
      "metadata": {
        "id": "o3rOSRKHCL4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize \n",
        "\n",
        "without : numbers, punctuations , emails and urls"
      ],
      "metadata": {
        "id": "vqGyoLDUuw_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [\"\",\".\"]\n",
        "Terms = []\n",
        "def Tokenize(text):\n",
        "    text = re.sub(r\"[^a-zA-Z]\",\" \",text)\n",
        "    text = re.sub(r\"Ã¢.*\",\"\",text)\n",
        "    text = text.replace(\"\\n\", \"\")\n",
        "    text = text.replace(\"@\", \"\")\n",
        "    text = text.replace(\".\", \"\")\n",
        "    text = word_tokenize(text)\n",
        "    text = [t for t in text if t not in empty]\n",
        "    Terms.extend(text)\n",
        "\n",
        "for row in df['Tweets'] :\n",
        "    Tokenize(row)      "
      ],
      "metadata": {
        "id": "PMYiqeDZnOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Terms[5:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyBCewuZ9X-F",
        "outputId": "f480a70d-9820-4eef-d57a-a25e5a1d6d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first', 'date', 'going', 'on', 'near', 'me']"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Size of tokenized terms is 3,407,224 Bytes\n"
      ],
      "metadata": {
        "id": "Q-iZ7Ix1u0_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:,}'.format(sys.getsizeof(Terms)),\"Bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRtdK_9jntdX",
        "outputId": "d794a8dd-c470-41d7-c20e-9247892aa897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3,407,224 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove duplicated words => term type\n",
        "\n",
        "for fixed space the dictinary size is **790,700 Bytes**"
      ],
      "metadata": {
        "id": "7p4Jm5rm139t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TermsTypes = list(dict.fromkeys(Terms))\n",
        "print('{:,}'.format(len(TermsTypes)*20),\"Bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5_5IiRzoE66",
        "outputId": "b00760f5-3a7e-418f-d36e-83d718c7cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "790,700 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the terms"
      ],
      "metadata": {
        "id": "LbQEWi9u48bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TermsTypes = sorted(TermsTypes)"
      ],
      "metadata": {
        "id": "RHtblvZF47ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TermsTypes[800:805]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0v-p4WL9QPl",
        "outputId": "113066dd-96b4-4fbc-e15d-dd952fa5d16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Animator', 'Anime', 'Aniston', 'Anita', 'AnithaSampath']"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Casefolding\n",
        "--fixed size terms storing--\n",
        "\n",
        "after Casefolding size is now **614,240 Bytes**\n",
        "\n",
        "decreased by ~22.3%\n"
      ],
      "metadata": {
        "id": "ULANGJ0zIEjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TermsCaseFold = [ term.casefold() for term in TermsTypes ]\n",
        "TermsCaseFold = list(dict.fromkeys(TermsCaseFold))\n",
        "TermsCaseFold[50:55]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGNeZ_oxB4HR",
        "outputId": "a497a9b8-02e9-49d3-a01b-0584a7451275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['admin', 'admire', 'admission', 'adorable', 'adore']"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:,}'.format(len(TermsCaseFold)*20),\"Bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2D5UF6az1bv",
        "outputId": "14c6a866-3421-4859-be45-96d2aa3280bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "614,240 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing stopwords\n",
        "\n",
        "--fixed size terms storing--\n",
        "\n",
        "after Removing stopwords size of dictinary is now **598,220 Bytes**\n",
        "\n",
        "decreased by ~2.6%"
      ],
      "metadata": {
        "id": "Fo3dW83pILJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopWords = pd.read_csv(\"https://raw.githubusercontent.com/bbalet/stopwords/master/_stopwords.txt\")\n",
        "stopWords = list(stopWords.iloc[2:,:].values)\n",
        "\n",
        "TermsCaseFold_without_stopwords = [t for t in TermsCaseFold if t not in stopWords]"
      ],
      "metadata": {
        "id": "_7WlZy9U8_Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:,}'.format(len(TermsCaseFold_without_stopwords)*20),\"Bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJz1iqDw0X14",
        "outputId": "735be2f4-26ea-495c-ed1f-f7d0eccc21b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "598,220 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "--fixed size terms storing--\n",
        "\n",
        "after Removing stopwords size of dictinary is now **493,460 Bytes**\n",
        "\n",
        "decreased by ~17.5%"
      ],
      "metadata": {
        "id": "aaA_me_U3jFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = ps()\n",
        "TermsStemmed = []\n",
        "for w in TermsCaseFold_without_stopwords:\n",
        "    TermsStemmed.append(ps.stem(w))\n",
        "\n",
        "TermsStemmed = list(dict.fromkeys(TermsStemmed))"
      ],
      "metadata": {
        "id": "IN7sUin93vWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{:,}'.format(len(TermsStemmed)*20),\"Bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B85xCzE4tla",
        "outputId": "9c138799-0312-41e1-918d-13aa375d83a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493,460 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Posting lists"
      ],
      "metadata": {
        "id": "KdxxdVDKCX8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "now lets make the posting list\n",
        "\n",
        "no need to sort the posting list with this algorithm\n",
        "\n",
        "the documents are implicitly sorted"
      ],
      "metadata": {
        "id": "jzgMhdp82211"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makePostings(Words,casefold=False):\n",
        "    global PostingLists\n",
        "    PostingLists = []\n",
        "    for number,term in enumerate(Words) :\n",
        "        print(number,\"/\",len(Words))\n",
        "        if casefold :\n",
        "           PostingList=df['Tweets'].str.casefold().str.contains(term)\n",
        "        PostingList=df['Tweets'].str.contains(term)   \n",
        "        PostingList=np.where(PostingList)[0]\n",
        "        PostingLists.append(PostingList)\n",
        "        clear_output() \n",
        "\n",
        "\n",
        "makePostings(TermsTypes)"
      ],
      "metadata": {
        "id": "mKm87T_A3op5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"term is : \",TermsTypes[400],\"\\nposting list is :\",PostingLists[400][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lZQfwnc9jW_",
        "outputId": "6c36e661-0043-4533-eb05-48f4d76601c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "term is :  Adam \n",
            "posting list is : [ 894 2407 3192 4008 4012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the dictionary has the terms without casefolding and without removing the stops words\n",
        "\n",
        "the size of posting lists is : 4,433,464 Bytes"
      ],
      "metadata": {
        "id": "rdu6Gz8Q7O95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sizeOfPosting():\n",
        "   Size_Of_Postings = sys.getsizeof(PostingLists)\n",
        "\n",
        "   for Post in PostingLists :\n",
        "       Size_Of_Postings += sys.getsizeof(Post)\n",
        "\n",
        "   print('{:,}'.format(Size_Of_Postings),\"Bytes\")  \n",
        "\n",
        "sizeOfPosting()   "
      ],
      "metadata": {
        "id": "YiDUr-Xk7w2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Casefolding Size of postings has been decreased by ~22.2%"
      ],
      "metadata": {
        "id": "yIx4AxHVEKBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "makePostings(TermsCaseFold,True)\n",
        "sizeOfPosting()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coTzK1xkEF2L",
        "outputId": "46ab4b74-7a2e-4627-fb2f-b13f0c5320f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3,448,088 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Removing stopwords Size of postings has been decreased by ~2.42%"
      ],
      "metadata": {
        "id": "QtCHEIPl71tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "makePostings(TermsCaseFold_without_stopwords,True)\n",
        "sizeOfPosting()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2emWI2gI--CO",
        "outputId": "956eaad1-64e6-4e61-c0b5-5e38d37e3922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3,364,368 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Stemming Size of postings has been decreased by ~17.7%"
      ],
      "metadata": {
        "id": "KzmcdW3I8BO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "makePostings(TermsStemmed,True)\n",
        "sizeOfPosting()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FN-YcW36r41",
        "outputId": "e1b48c28-e1ac-4b00-aae4-e81fb6321fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2,766,304 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compressing \n",
        "\n",
        "using :\n",
        "\n",
        "1. one-String dictinary\n",
        "2. one-String dictinary with blocking"
      ],
      "metadata": {
        "id": "PvCW3ppF1Lvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After storing the terms in one-string\n",
        "\n",
        "and store reference to the terms the size is **382,173 Bytes**\n",
        "\n",
        "decreased by ~22.5%"
      ],
      "metadata": {
        "id": "aD1h1kpQ1_mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_of_terms = []\n",
        "dictionary_string = ''\n",
        "\n",
        "for term in TermsStemmed :\n",
        "    dictionary_string += term\n",
        "    reference_of_terms.append(len(dictionary_string)-len(term))\n",
        "    \n",
        "print('{:,}'.format(sys.getsizeof(reference_of_terms)+sys.getsizeof(dictionary_string)),\"Bytes\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjF2JUTYmfHJ",
        "outputId": "5b888e46-02ce-493d-b318-c75c45e19062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "382,173 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying block concept to one-string dictinary\n",
        "\n",
        "and store reference to the terms the size is **347,322 Bytes**\n",
        "\n",
        "decreased by ~9.11%\n",
        "\n",
        "block size = 8"
      ],
      "metadata": {
        "id": "KEwz64sp2lq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_of_terms = []\n",
        "dictionary_string = ''\n",
        "block = 8\n",
        "\n",
        "for term in TermsStemmed :\n",
        "    dictionary_string += str(len(dictionary_string)-len(term)) + term\n",
        "\n",
        "    block -= 1\n",
        "    if block == 0 :\n",
        "       reference_of_terms.append(len(dictionary_string)-len(term))\n",
        "       block = 8\n",
        "\n",
        "print('{:,}'.format(sys.getsizeof(reference_of_terms)+sys.getsizeof(dictionary_string)),\"Bytes\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oR8kyJ0nacZ",
        "outputId": "f830394a-9616-49b1-bf9e-3552d146ee7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347,322 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "| memory size in bytes of :> | dictionary | cumulative Percentage | non-postitional posting lists |cumulative Percentage |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| No numbers | -- | -- | -- |--|\n",
        "| Case Folding| 22.3%| 22.3% | 22.2% |22.2% |\n",
        "| Stop words |2.6%| 24.9% | 2.24% |24.44% |\n",
        "| Stemming |17.5| 42.4% | 17.7% | 42.14% |\n",
        "| one-String |22.5%| 64.9% |--|42.14% |\n",
        "| one-String+blocking=8 |9.11%| 74.01% |--|42.14% |"
      ],
      "metadata": {
        "id": "-zP_4mH5Nndx"
      }
    }
  ]
}